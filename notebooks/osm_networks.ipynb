{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import geopandas as geopd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as geopd\n",
    "import shapely\n",
    "from shapely import ops\n",
    "import pyproj\n",
    "import requests\n",
    "from itertools import chain\n",
    "from modules import utils\n",
    "from networkx import bfs_edges\n",
    "\n",
    "import modules.network_extractor as net_ex\n",
    "import modules.networker as netw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.network_extractor as net_ex\n",
    "from modules.networker import Networker\n",
    "extractor = net_ex.NetworkExtractor()\n",
    "extractor.DATA_BASE_PATH = \"/home/user/Desktop/JP/street-network-indices/data\"\n",
    "networker = Networker()\n",
    "\n",
    "folder = \"bogota\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.RankWarning) \n",
    "\n",
    "extractor = net_ex.NetworkExtractor()\n",
    "extractor.DATA_BASE_PATH = \"/home/user/Desktop/JP/street-network-indices/data\"\n",
    "networker = netw.Networker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_centers: geopd.GeoDataFrame\n",
    "\n",
    "urban_centers = geopd.read_file(\n",
    "    \"/home/user/Desktop/JP/street-network-indices/data/GHS_URBAN_CENTERS/GHS_URBAN_SIMPLIFIED_fixed.gpkg\",\n",
    "    layer='GHS_URBAN_SIMPLIFIED_fixed'    \n",
    ")\n",
    "urban_centers = urban_centers.rename(columns={\n",
    "    \"GC_POP_TOT_2025\": \"population\",\n",
    "    \"GC_UCA_KM2_2025\": \"area\",\n",
    "    \"GC_DEV_USR_2025\": \"continent\",\n",
    "    \"GC_UCN_MAI_2025\": \"name\",\n",
    "    \"GC_CNT_GAD_2025\": \"country\"\n",
    "})\n",
    "transform = pyproj.Transformer.from_crs(\"ESRI:54009\", \"EPSG:4326\", always_xy=True).transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = {\n",
    "    \"buenos_aires\": {\"search\": \"Buenos Aires\", \"country\": \"Argentina\"},\n",
    "    \"bogota\": {\"search\": \"Bogota\", \"country\": \"Colombia\"},\n",
    "    \"lima\": {\"search\": \"Lima\", \"country\": \"Peru\"},\n",
    "    \"chicago\": {\"search\": \"Chicago\", \"country\": \"United States\"},\n",
    "    \"ottawa\": {\"search\": \"Ottawa\", \"country\": \"Canada\"},\n",
    "    \"mexico_city\": {\"search\": \"Mexico City\", \"country\": \"MÃ©xico\"},\n",
    "    \"panama_city\": {\"search\": \"Panama City\", \"country\": \"Panama\"},\n",
    "    \"san_salvador\": {\"search\": \"San Salvador\", \"country\": \"El Salvador\"},\n",
    "    \"havana\": {\"search\": \"Havana\", \"country\": \"Cuba\"},\n",
    "    \"milan\": {\"search\": \"Milan\", \"country\": \"Italy\"},\n",
    "    \"madrid\": {\"search\": \"Madrid\", \"country\": \"Spain\"},\n",
    "    \"athens\": {\"search\": \"Athens\", \"country\": \"Greece\"},\n",
    "    \"osaka\": {\"search\": \"Osaka\", \"country\": \"Japan\"},\n",
    "    \"shanghai\": {\"search\": \"Shanghai\", \"country\": \"China\"},\n",
    "    \"hanoi\": {\"search\": \"Hanoi\", \"country\": \"Vietnam\"},\n",
    "    \"dubai\": {\"search\": \"Dubai\", \"country\": \"United Arab Emirates\"},\n",
    "    \"riyadh\": {\"search\": \"Riyadh\", \"country\": \"Saudi Arabia\"},\n",
    "    \"doha\": {\"search\": \"Doha\", \"country\": \"Qatar\"},\n",
    "    \"wellington\": {\"search\": \"Wellington\", \"country\": \"New Zealand\"},\n",
    "    \"sydney\": {\"search\": \"Sydney\", \"country\": \"Australia\"},\n",
    "    \"port_moresby\": {\"search\": \"Port Moresby\", \"country\": \"Papua New Guinea\"},\n",
    "    \"lagos\": {\"search\": \"Lagos\", \"country\": \"Nigeria\"},\n",
    "    \"alexandria\": {\"search\": \"Alexandria\", \"country\": \"Egypt\"},\n",
    "    \"pretoria\": {\"search\": \"Pretoria\", \"country\": \"South Africa\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Area 114\n",
      "extracting Bologna\n",
      "/home/user/Desktop/JP/street-network-indices/data/DEM/Bologna_DEM.tif: No such file or directory\n",
      "error in city {'search': 'Bologna', 'country': 'Italy'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(ex)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in city \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m stats\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextractor\u001b[38;5;241m.\u001b[39mDATA_BASE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Research/.venv/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Desktop/Research/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Research/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Desktop/Research/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "stats_dict = {\n",
    "    \"city\": [],\n",
    "    \"area\": [],\n",
    "    \"population\": [],\n",
    "    \"drive_nodes\": [],\n",
    "    \"drive_edges\": [],\n",
    "    \"bike_nodes\": [],\n",
    "    \"bike_edges\": [],\n",
    "    \"walk_nodes\": [],\n",
    "    \"walk_edges\": [],\n",
    "    \"total_time\": []\n",
    "}\n",
    "\n",
    "def add_stat(stats, stat, value):\n",
    "    stats[stat].append(value)\n",
    "\n",
    "# Extract the networks for the cities and save statistics about each one\n",
    "for folder, city in cities.items():\n",
    "    try:\n",
    "        city_info = urban_centers.loc[\n",
    "            (urban_centers[\"name\"] == city[\"search\"]) &\n",
    "            (urban_centers[\"country\"] == city[\"country\"])\n",
    "        ]\n",
    "\n",
    "        geometry = city_info[\"geometry\"].values[0]\n",
    "        geom_reprojected = ops.transform(transform, geometry)\n",
    "\n",
    "        add_stat(stats_dict, \"area\", city_info[\"area\"].values[0])\n",
    "        add_stat(stats_dict, \"population\", int(city_info[\"population\"].values[0]))\n",
    "        print(f\"Total Area {city_info['area'].values[0]}\")\n",
    "\n",
    "        # start timer to check time to download graphs for the city.\n",
    "        start = time.time()\n",
    "        city_name = city[\"search\"]\n",
    "        add_stat(stats_dict, \"city\", city_name)\n",
    "        print(f\"extracting {city_name}\")\n",
    "        place = city_name\n",
    "        stat_row = {}\n",
    "\n",
    "        # Extract driving graph and save statistics\n",
    "        city_drive = extractor.extract_network(\"drive\", place, geometry=geom_reprojected)\n",
    "        networker.add_elevation(city_drive, city_name=city_name, cpus=4)\n",
    "        #add_edge_slope(city_drive)\n",
    "        ox.add_edge_grades(city_drive)\n",
    "        ox.add_edge_bearings(city_drive)\n",
    "        add_stat(stats_dict, \"drive_nodes\", city_drive.number_of_nodes())\n",
    "        add_stat(stats_dict, \"drive_edges\", city_drive.number_of_edges())\n",
    "        \n",
    "        # Extract bike graph and save statistics\n",
    "        city_bike = extractor.extract_network(\"bike\", place, geometry=geom_reprojected)\n",
    "        networker.add_elevation(city_bike, city_name=city_name, cpus=4)\n",
    "        #add_edge_slope(city_bike)\n",
    "        ox.add_edge_grades(city_bike)\n",
    "        ox.add_edge_bearings(city_bike)\n",
    "        add_stat(stats_dict, \"bike_nodes\", city_bike.number_of_nodes())\n",
    "        add_stat(stats_dict, \"bike_edges\", city_bike.number_of_edges())\n",
    "\n",
    "        # Extract pedestrian graph and save statistics\n",
    "        city_walk = extractor.extract_network(\"walk\", place, geometry=geom_reprojected)\n",
    "        networker.add_elevation(city_walk, city_name=city_name, cpus=4)\n",
    "        #add_edge_slope(city_walk)\n",
    "        ox.add_edge_grades(city_walk)\n",
    "        ox.add_edge_bearings(city_walk)\n",
    "        add_stat(stats_dict, \"walk_nodes\", city_walk.number_of_nodes())\n",
    "        add_stat(stats_dict, \"walk_edges\", city_walk.number_of_edges())\n",
    "\n",
    "        print(\"Saving the city graphs\")\n",
    "        # Saving the city graphs\n",
    "        base_folder = f\"{extractor.DATA_BASE_PATH}/{folder}/graph\"\n",
    "        Path(base_folder).mkdir(parents=True, exist_ok=True)\n",
    "        extractor.save_as_graph(city_drive, f\"{folder}/graph/{folder}_drive\")\n",
    "        extractor.save_as_graph(city_bike, f\"{folder}/graph/{folder}_bike\")\n",
    "        extractor.save_as_graph(city_walk, f\"{folder}/graph/{folder}_walk\")\n",
    "\n",
    "        end = time.time()\n",
    "        total_time = end-start\n",
    "        stat_row[\"total_time\"] = total_time\n",
    "\n",
    "        add_stat(stats_dict, \"total_time\", total_time)\n",
    "        print(f\"{city_name} Finished!\")\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        print(f\"error in city {city}\")\n",
    "\n",
    "stats = pd.DataFrame(stats_dict)\n",
    "stats.to_csv(f\"{extractor.DATA_BASE_PATH}/stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': ['Bologna'],\n",
       " 'area': [114],\n",
       " 'population': [456780],\n",
       " 'drive_nodes': [],\n",
       " 'drive_edges': [],\n",
       " 'bike_nodes': [],\n",
       " 'bike_edges': [],\n",
       " 'walk_nodes': [],\n",
       " 'walk_edges': [],\n",
       " 'total_time': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading a graph after downloading\n",
    "folder = \"athens\"\n",
    "g_walk = extractor.load_graph(f\"{folder}/graph/{folder}_walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176348"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_walk.number_of_edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
